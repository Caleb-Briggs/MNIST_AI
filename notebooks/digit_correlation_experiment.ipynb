{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Correlation Experiment\n",
    "\n",
    "Train 50 models on balanced samples (2 per digit = 20 total), then analyze digit-by-digit accuracy correlations across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Caleb-Briggs/MNIST_AI.git\n",
    "%cd MNIST_AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils.data import load_mnist, get_device\n",
    "from utils.models import SmallCNN\n",
    "from utils.evaluation import get_predictions\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 50\n",
    "SAMPLES_PER_DIGIT = 2\n",
    "TARGET_TRAIN_ACC = 0.99\n",
    "MAX_EPOCHS = 200\n",
    "LR = 1e-3\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_mnist(device, train=True)\n",
    "test_images, test_labels = load_mnist(device, train=False)\n",
    "\n",
    "digit_indices = {d: (labels == d).nonzero(as_tuple=True)[0].cpu().numpy() for d in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_sample(digit_indices, samples_per_digit, rng):\n",
    "    indices = []\n",
    "    for d in range(10):\n",
    "        chosen = rng.choice(digit_indices[d], size=samples_per_digit, replace=False)\n",
    "        indices.extend(chosen)\n",
    "    return np.array(indices)\n",
    "\n",
    "def train_until_accuracy(model, images, labels, indices, target_acc, max_epochs, lr):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    X = images[indices]\n",
    "    y = labels[indices]\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = output.argmax(dim=1)\n",
    "            acc = (preds == y).float().mean().item()\n",
    "        \n",
    "        if acc >= target_acc:\n",
    "            return epoch + 1, acc\n",
    "    \n",
    "    return max_epochs, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training {NUM_MODELS} models on {SAMPLES_PER_DIGIT * 10} samples each...\")\n",
    "\n",
    "models = []\n",
    "training_indices = []\n",
    "epochs_to_converge = []\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "for i in tqdm(range(NUM_MODELS)):\n",
    "    indices = create_balanced_sample(digit_indices, SAMPLES_PER_DIGIT, rng)\n",
    "    training_indices.append(indices)\n",
    "    \n",
    "    model = SmallCNN().to(device)\n",
    "    epochs, _ = train_until_accuracy(model, images, labels, indices, TARGET_TRAIN_ACC, MAX_EPOCHS, LR)\n",
    "    \n",
    "    models.append(model)\n",
    "    epochs_to_converge.append(epochs)\n",
    "\n",
    "print(f\"Epochs to converge: {np.mean(epochs_to_converge):.1f} ± {np.std(epochs_to_converge):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "\n",
    "all_correct = np.zeros((NUM_MODELS, len(test_labels)), dtype=bool)\n",
    "\n",
    "for i, model in enumerate(tqdm(models)):\n",
    "    result = get_predictions(model, test_images, test_labels)\n",
    "    all_correct[i] = result['correct']\n",
    "\n",
    "model_accuracies = all_correct.mean(axis=1)\n",
    "print(f\"Test accuracy: {model_accuracies.mean():.4f} ± {model_accuracies.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_np = test_labels.cpu().numpy()\n",
    "digit_accuracies = np.zeros((NUM_MODELS, 10))\n",
    "\n",
    "for d in range(10):\n",
    "    digit_mask = test_labels_np == d\n",
    "    digit_accuracies[:, d] = all_correct[:, digit_mask].mean(axis=1)\n",
    "\n",
    "print(\"Per-digit accuracy (mean ± std):\")\n",
    "for d in range(10):\n",
    "    print(f\"  {d}: {digit_accuracies[:, d].mean():.4f} ± {digit_accuracies[:, d].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_corr = np.corrcoef(digit_accuracies.T)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(digit_corr, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_yticks(range(10))\n",
    "ax.set_xlabel('Digit')\n",
    "ax.set_ylabel('Digit')\n",
    "ax.set_title('Digit-Digit Accuracy Correlation Across Models')\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if abs(digit_corr[i, j]) > 0.5 else 'black'\n",
    "        ax.text(j, i, f'{digit_corr[i, j]:.2f}', ha='center', va='center', fontsize=8, color=color)\n",
    "\n",
    "plt.colorbar(im, label='Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_difficulty = all_correct.mean(axis=0)\n",
    "\n",
    "print(f\"Sample difficulty:\")\n",
    "print(f\"  Always correct: {(sample_difficulty == 1.0).sum()}\")\n",
    "print(f\"  >80% correct: {(sample_difficulty > 0.8).sum()}\")\n",
    "print(f\"  <50% correct: {(sample_difficulty < 0.5).sum()}\")\n",
    "print(f\"  Always wrong: {(sample_difficulty == 0.0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_corr = np.corrcoef(all_correct)\n",
    "off_diag = model_corr[np.triu_indices(NUM_MODELS, k=1)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "im = axes[0].imshow(model_corr, cmap='viridis')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Model')\n",
    "axes[0].set_title('Model-Model Correlation')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "\n",
    "axes[1].hist(off_diag, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(off_diag.mean(), color='red', linestyle='--', label=f'Mean: {off_diag.mean():.3f}')\n",
    "axes[1].set_xlabel('Correlation')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Model-model correlation: {off_diag.mean():.4f} ± {off_diag.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 10, figsize=(15, 6))\n",
    "\n",
    "for d in range(10):\n",
    "    digit_mask = test_labels_np == d\n",
    "    digit_idx = np.where(digit_mask)[0]\n",
    "    digit_diff = sample_difficulty[digit_mask]\n",
    "    sorted_idx = digit_idx[np.argsort(digit_diff)]\n",
    "    \n",
    "    for row, idx in enumerate(sorted_idx[:3]):\n",
    "        axes[row, d].imshow(test_images[idx, 0].cpu().numpy(), cmap='gray')\n",
    "        axes[row, d].set_title(f'{sample_difficulty[idx]:.0%}', fontsize=9)\n",
    "        axes[row, d].axis('off')\n",
    "    \n",
    "    easiest = sorted_idx[-1]\n",
    "    axes[3, d].imshow(test_images[easiest, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[3, d].set_title(f'{sample_difficulty[easiest]:.0%}', fontsize=9)\n",
    "    axes[3, d].axis('off')\n",
    "\n",
    "for d in range(10):\n",
    "    axes[3, d].set_xlabel(f'{d}', fontsize=10)\n",
    "\n",
    "axes[0, 0].set_ylabel('Hardest', fontsize=10)\n",
    "axes[1, 0].set_ylabel('2nd', fontsize=10)\n",
    "axes[2, 0].set_ylabel('3rd', fontsize=10)\n",
    "axes[3, 0].set_ylabel('Easiest', fontsize=10)\n",
    "\n",
    "plt.suptitle('Hardest/Easiest Samples by Digit')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_corr_off = digit_corr[np.triu_indices(10, k=1)]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Models: {NUM_MODELS}, trained on {SAMPLES_PER_DIGIT * 10} samples each\")\n",
    "print(f\"Test accuracy: {model_accuracies.mean():.4f} ± {model_accuracies.std():.4f}\")\n",
    "print(f\"Model-model correlation: {off_diag.mean():.4f}\")\n",
    "print(f\"Inter-digit correlation: {digit_corr_off.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
