{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics Video Prediction - Training\n",
    "\n",
    "Train a transformer-based model to predict physics simulation frames.\n",
    "\n",
    "**Architecture**: CNN Encoder → Transformer → CNN Decoder\n",
    "\n",
    "**Goal**: Model learns to compress video to latent state that captures physics (position, velocity, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'MNIST_AI'...\n",
      "remote: Enumerating objects: 130, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
      "remote: Total 130 (delta 29), reused 45 (delta 16), pack-reused 72 (from 1)\u001b[K\n",
      "Receiving objects: 100% (130/130), 22.90 MiB | 27.92 MiB/s, done.\n",
      "Resolving deltas: 100% (48/48), done.\n",
      "/content/MNIST_AI/experiments/physics_prediction/MNIST_AI/experiments/physics_prediction/MNIST_AI/experiments/physics_prediction\n"
     ]
    }
   ],
   "source": [
    "# Clone repo (for Colab)\n",
    "!git clone https://github.com/Caleb-Briggs/MNIST_AI.git\n",
    "%cd MNIST_AI/experiments/physics_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from physics_sim import (\n",
    "    Ball, Barrier, PhysicsSimulation,\n",
    "    generate_trajectory, create_random_simulation, generate_dataset\n",
    ")\n",
    "from model import VideoPredictor, count_parameters\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Data config\nNUM_TRAJECTORIES = 2000  # Many trajectories for diverse terrains\nFRAMES_PER_TRAJECTORY = 50  # Enough frames for context + rollout\nNUM_BARRIERS = 3\nWITH_GRAVITY = False  # Start simple\n\n# Model config\nLATENT_DIM = 256\nN_HEADS = 4\nN_LAYERS = 4\nMIN_CONTEXT = 4   # Minimum context frames\nMAX_CONTEXT = 16  # Maximum context frames  \nPREDICT_STEPS = 3  # Always predict this many steps ahead\n\n# Training config\nBATCH_SIZE = 64  # Smaller batch since samples have variable sizes\nLEARNING_RATE = 3e-4\nNUM_EPOCHS = 50\nSEED = 42\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\nprint(f\"Context length: {MIN_CONTEXT} to {MAX_CONTEXT} frames\")\nprint(f\"Predict {PREDICT_STEPS} steps from each context\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Dataset shape: (2000, 50, 64, 64)\n",
      "Memory: 1562.5 MB\n",
      "Tensor shape: torch.Size([2000, 50, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating training data...\")\n",
    "data = generate_dataset(\n",
    "    num_trajectories=NUM_TRAJECTORIES,\n",
    "    num_frames=FRAMES_PER_TRAJECTORY,\n",
    "    num_barriers=NUM_BARRIERS,\n",
    "    with_gravity=WITH_GRAVITY,\n",
    "    base_seed=SEED\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Memory: {data.nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Convert to torch tensor\n",
    "data_tensor = torch.from_numpy(data).float().unsqueeze(2)  # Add channel dim: (N, T, 1, H, W)\n",
    "print(f\"Tensor shape: {data_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 1 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3347753263.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf't={t}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for axis 1 with size 50"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 24 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize a few trajectories\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "for row in range(3):\n",
    "    for col in range(8):\n",
    "        t = col * 10\n",
    "        axes[row, col].imshow(data[row, t], cmap='gray', vmin=0, vmax=1)\n",
    "        if row == 0:\n",
    "            axes[row, col].set_title(f't={t}')\n",
    "        axes[row, col].axis('off')\n",
    "plt.suptitle('Sample Trajectories')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class PhysicsDataset(torch.utils.data.Dataset):\n    \"\"\"Dataset with variable-length context windows.\n    \n    For each trajectory, we create multiple samples:\n    - Context frames 0:4, predict 4:7\n    - Context frames 0:5, predict 5:8\n    - Context frames 0:6, predict 6:9\n    - ... up to max_context\n    \n    This trains the model to handle varying context lengths.\n    \"\"\"\n    \n    def __init__(self, trajectories: torch.Tensor, min_context: int, max_context: int, predict_steps: int):\n        \"\"\"\n        Args:\n            trajectories: (num_traj, num_frames, 1, H, W)\n            min_context: minimum number of context frames\n            max_context: maximum number of context frames\n            predict_steps: number of future frames to predict\n        \"\"\"\n        self.trajectories = trajectories\n        self.min_context = min_context\n        self.max_context = max_context\n        self.predict_steps = predict_steps\n        self.num_traj = trajectories.size(0)\n        self.num_frames = trajectories.size(1)\n        \n        # Build index of all valid (trajectory, context_len) pairs\n        self.samples = []\n        for traj_idx in range(self.num_traj):\n            for ctx_len in range(min_context, max_context + 1):\n                # Need ctx_len context frames + predict_steps target frames\n                if ctx_len + predict_steps <= self.num_frames:\n                    self.samples.append((traj_idx, ctx_len))\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        traj_idx, ctx_len = self.samples[idx]\n        \n        # Context: frames 0 to ctx_len (variable length)\n        # Targets: frames ctx_len to ctx_len + predict_steps\n        context = self.trajectories[traj_idx, :ctx_len]  # (ctx_len, 1, 64, 64)\n        targets = self.trajectories[traj_idx, ctx_len:ctx_len + self.predict_steps]  # (predict_steps, 1, 64, 64)\n        \n        return context, targets\n\n\ndef collate_variable_context(batch):\n    \"\"\"Custom collate function to pad variable-length contexts.\"\"\"\n    contexts, targets = zip(*batch)\n    \n    # Find max context length in this batch\n    max_ctx = max(c.size(0) for c in contexts)\n    \n    # Pad contexts to max length (pad at the beginning with zeros)\n    padded_contexts = []\n    context_lengths = []\n    for ctx in contexts:\n        ctx_len = ctx.size(0)\n        context_lengths.append(ctx_len)\n        if ctx_len < max_ctx:\n            # Pad at beginning: [0, 0, ..., actual_frames]\n            padding = torch.zeros(max_ctx - ctx_len, *ctx.shape[1:])\n            padded = torch.cat([padding, ctx], dim=0)\n        else:\n            padded = ctx\n        padded_contexts.append(padded)\n    \n    # Stack into batches\n    contexts_batch = torch.stack(padded_contexts)  # (batch, max_ctx, 1, 64, 64)\n    targets_batch = torch.stack(targets)  # (batch, predict_steps, 1, 64, 64)\n    lengths_batch = torch.tensor(context_lengths)  # (batch,)\n    \n    return contexts_batch, targets_batch, lengths_batch\n\n\n# Split into train/val\ntrain_size = int(0.9 * NUM_TRAJECTORIES)\ntrain_data = data_tensor[:train_size]\nval_data = data_tensor[train_size:]\n\ntrain_dataset = PhysicsDataset(train_data, MIN_CONTEXT, MAX_CONTEXT, PREDICT_STEPS)\nval_dataset = PhysicsDataset(val_data, MIN_CONTEXT, MAX_CONTEXT, PREDICT_STEPS)\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n    num_workers=4, pin_memory=True, collate_fn=collate_variable_context\n)\nval_loader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n    num_workers=4, pin_memory=True, collate_fn=collate_variable_context\n)\n\nprint(f\"Train samples: {len(train_dataset)} ({train_size} trajectories × {MAX_CONTEXT - MIN_CONTEXT + 1} context lengths)\")\nprint(f\"Val samples: {len(val_dataset)}\")\nprint(f\"Each sample: variable context ({MIN_CONTEXT}-{MAX_CONTEXT} frames) -> {PREDICT_STEPS} target frames\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def create_padding_mask(batch_size, max_len, actual_lengths, device):\n    \"\"\"Create padding mask: True for padded positions (at the beginning).\"\"\"\n    mask = torch.zeros(batch_size, max_len, dtype=torch.bool, device=device)\n    for i, length in enumerate(actual_lengths):\n        pad_len = max_len - length\n        if pad_len > 0:\n            mask[i, :pad_len] = True\n    return mask\n\n\nmodel = VideoPredictor(\n    latent_dim=LATENT_DIM,\n    n_heads=N_HEADS,\n    n_layers=N_LAYERS,\n    dim_feedforward=LATENT_DIM * 2,\n    dropout=0.1\n).to(device)\n\nprint(f\"Model parameters: {count_parameters(model):,}\")\n\n# Test forward pass with variable context\nsample_context, sample_target, sample_lengths = next(iter(train_loader))\nsample_context = sample_context.to(device)\nsample_lengths = sample_lengths.to(device)\n\n# Create padding mask for test\nbatch_size = sample_context.size(0)\nmax_ctx = sample_context.size(1)\npadding_mask = create_padding_mask(batch_size, max_ctx, sample_lengths, device)\n\nwith torch.no_grad():\n    sample_pred = model(sample_context, n_future=PREDICT_STEPS, padding_mask=padding_mask)\n\nprint(f\"Context shape: {sample_context.shape}\")\nprint(f\"Context lengths: min={sample_lengths.min().item()}, max={sample_lengths.max().item()}\")\nprint(f\"Output shape: {sample_pred.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# Loss function: MSE on pixels\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'lr': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_epoch(model, loader, optimizer, criterion, device, predict_steps):\n    \"\"\"Train with variable-length context and parallel multi-step prediction.\"\"\"\n    model.train()\n    total_loss = 0\n    total_samples = 0\n    \n    for context, targets, lengths in loader:\n        context = context.to(device)  # (batch, max_ctx, 1, 64, 64)\n        targets = targets.to(device)  # (batch, predict_steps, 1, 64, 64)\n        lengths = lengths.to(device)  # (batch,)\n        \n        batch_size = context.size(0)\n        max_ctx = context.size(1)\n        \n        # Create padding mask\n        padding_mask = create_padding_mask(batch_size, max_ctx, lengths, device)\n        \n        optimizer.zero_grad()\n        \n        # Predict future frames with padding mask\n        preds = model(context, n_future=predict_steps, padding_mask=padding_mask)\n        \n        # MSE loss over all predicted frames\n        loss = criterion(preds, targets)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item() * batch_size\n        total_samples += batch_size\n    \n    return total_loss / total_samples\n\n\n@torch.no_grad()\ndef eval_epoch(model, loader, criterion, device, predict_steps):\n    \"\"\"Evaluate with variable-length context.\"\"\"\n    model.eval()\n    total_loss = 0\n    total_samples = 0\n    \n    for context, targets, lengths in loader:\n        context = context.to(device)\n        targets = targets.to(device)\n        lengths = lengths.to(device)\n        \n        batch_size = context.size(0)\n        max_ctx = context.size(1)\n        \n        padding_mask = create_padding_mask(batch_size, max_ctx, lengths, device)\n        preds = model(context, n_future=predict_steps, padding_mask=padding_mask)\n        \n        loss = criterion(preds, targets)\n        total_loss += loss.item() * batch_size\n        total_samples += batch_size\n    \n    return total_loss / total_samples\n\n\n@torch.no_grad()\ndef quick_visualize(model, val_data, device, epoch, min_ctx=4, max_ctx=16):\n    \"\"\"Quick visualization during training - shows predictions at different context lengths.\"\"\"\n    model.eval()\n    \n    fig, axes = plt.subplots(3, 6, figsize=(15, 7.5))\n    \n    # Row 0: Short context (min_ctx frames)\n    # Row 1: Medium context (mid frames)  \n    # Row 2: Long context (max_ctx frames)\n    context_lengths = [min_ctx, (min_ctx + max_ctx) // 2, max_ctx]\n    \n    for row, ctx_len in enumerate(context_lengths):\n        # Get context from first trajectory\n        context = val_data[0, :ctx_len].unsqueeze(0).to(device)\n        target = val_data[0, ctx_len:ctx_len+3]  # 3 target frames\n        \n        # Predict\n        pred = model(context, n_future=3).cpu().squeeze(0)  # (3, 1, 64, 64)\n        \n        # Show last 2 context frames\n        for i in range(2):\n            frame_idx = ctx_len - 2 + i\n            axes[row, i].imshow(context[0, -2+i, 0].cpu(), cmap='gray', vmin=0, vmax=1)\n            axes[row, i].set_title(f'Ctx t={frame_idx}' if row == 0 else '')\n            axes[row, i].axis('off')\n        \n        # Show 2 predictions vs ground truth (interleaved)\n        for t in range(2):\n            # Predicted\n            axes[row, 2 + t*2].imshow(pred[t, 0].clamp(0, 1), cmap='gray', vmin=0, vmax=1)\n            axes[row, 2 + t*2].set_title(f'Pred t+{t+1}' if row == 0 else '')\n            axes[row, 2 + t*2].axis('off')\n            \n            # Ground truth\n            axes[row, 3 + t*2].imshow(target[t, 0], cmap='gray', vmin=0, vmax=1)\n            axes[row, 3 + t*2].set_title(f'GT t+{t+1}' if row == 0 else '')\n            axes[row, 3 + t*2].axis('off')\n        \n        # Label rows\n        axes[row, 0].set_ylabel(f'ctx={ctx_len}', fontsize=12)\n    \n    plt.suptitle(f'Epoch {epoch} - Predictions at Different Context Lengths')\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualization frequency\nVIS_EVERY = 10  # Show visualizations every N epochs\n\nprint(f\"Training for {NUM_EPOCHS} epochs...\")\nprint(f\"Variable context: {MIN_CONTEXT}-{MAX_CONTEXT} frames\")\nprint(f\"Predict {PREDICT_STEPS} steps ahead\")\nprint(\"=\"*60)\n\nfor epoch in range(NUM_EPOCHS):\n    train_loss = train_epoch(model, train_loader, optimizer, criterion, device, PREDICT_STEPS)\n    val_loss = eval_epoch(model, val_loader, criterion, device, PREDICT_STEPS)\n    \n    history['train_loss'].append(train_loss)\n    history['val_loss'].append(val_loss)\n    history['lr'].append(optimizer.param_groups[0]['lr'])\n    \n    scheduler.step()\n    \n    # Print progress\n    if (epoch + 1) % 5 == 0 or epoch == 0:\n        print(f\"Epoch {epoch+1:3d}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")\n    \n    # Periodic visualization\n    if (epoch + 1) % VIS_EVERY == 0 or epoch == 0:\n        quick_visualize(model, val_data, device, epoch + 1, MIN_CONTEXT, MAX_CONTEXT)\n\nprint(\"=\"*60)\nprint(\"Training complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations\n",
    "\n",
    "### Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('Training Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1].plot(history['lr'])\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Learning Rate')\n",
    "axes[1].set_title('Learning Rate Schedule')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Step Predictions vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef visualize_predictions(model, val_data, device, num_samples=5, context_len=8, num_future=5):\n    \"\"\"Show context, predictions at different horizons, and ground truth.\"\"\"\n    model.eval()\n    \n    # Columns: last 3 context frames + predicted/GT pairs\n    num_cols = 3 + num_future * 2\n    fig, axes = plt.subplots(num_samples, num_cols, figsize=(2*num_cols, 2.5*num_samples))\n    \n    indices = np.random.choice(len(val_data), num_samples, replace=False)\n    \n    for row, traj_idx in enumerate(indices):\n        context = val_data[traj_idx, :context_len].unsqueeze(0).to(device)\n        targets = val_data[traj_idx, context_len:context_len + num_future]\n        preds = model(context, n_future=num_future).cpu().squeeze(0)\n        \n        col = 0\n        # Show last 3 context frames\n        for i in range(3):\n            axes[row, col].imshow(context[0, -(3-i), 0].cpu(), cmap='gray', vmin=0, vmax=1)\n            if row == 0:\n                axes[row, col].set_title(f'Ctx t-{2-i}')\n            axes[row, col].axis('off')\n            col += 1\n        \n        # Show predicted and ground truth frames side by side\n        for t in range(num_future):\n            # Predicted\n            axes[row, col].imshow(preds[t, 0].clamp(0, 1), cmap='gray', vmin=0, vmax=1)\n            if row == 0:\n                axes[row, col].set_title(f'Pred t+{t+1}')\n            axes[row, col].axis('off')\n            col += 1\n            \n            # Ground truth\n            axes[row, col].imshow(targets[t, 0], cmap='gray', vmin=0, vmax=1)\n            if row == 0:\n                axes[row, col].set_title(f'GT t+{t+1}')\n            axes[row, col].axis('off')\n            col += 1\n    \n    plt.suptitle(f'Context ({context_len} frames) → Predictions vs Ground Truth')\n    plt.tight_layout()\n    plt.show()\n\n# Test at different context lengths\nfor ctx_len in [MIN_CONTEXT, (MIN_CONTEXT + MAX_CONTEXT) // 2, MAX_CONTEXT]:\n    print(f\"\\nContext length: {ctx_len}\")\n    visualize_predictions(model, val_data, device, num_samples=3, context_len=ctx_len, num_future=5)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef visualize_rollout(model, trajectories, device, traj_idx=0, context_len=8, rollout_steps=30):\n    \"\"\"Compare rollout with ground truth at a specific context length.\"\"\"\n    model.eval()\n    \n    # Get initial context\n    context = trajectories[traj_idx, :context_len].unsqueeze(0).to(device)\n    \n    # Ground truth future\n    gt_future = trajectories[traj_idx, context_len:context_len+rollout_steps].cpu().numpy()\n    \n    # Predict all future frames at once\n    predicted = model.rollout(context, rollout_steps).cpu().squeeze().numpy()\n    \n    # Visualize\n    num_show = min(10, rollout_steps)\n    step_indices = np.linspace(0, rollout_steps-1, num_show, dtype=int)\n    \n    fig, axes = plt.subplots(3, num_show, figsize=(2*num_show, 6))\n    \n    for col, t in enumerate(step_indices):\n        # Predicted\n        axes[0, col].imshow(predicted[t, 0], cmap='gray', vmin=0, vmax=1)\n        if col == 0:\n            axes[0, col].set_ylabel('Predicted')\n        axes[0, col].set_title(f't+{t+1}')\n        axes[0, col].axis('off')\n        \n        # Ground truth\n        axes[1, col].imshow(gt_future[t, 0], cmap='gray', vmin=0, vmax=1)\n        if col == 0:\n            axes[1, col].set_ylabel('Ground Truth')\n        axes[1, col].axis('off')\n        \n        # Error\n        error = np.abs(predicted[t, 0] - gt_future[t, 0])\n        axes[2, col].imshow(error, cmap='hot', vmin=0, vmax=0.5)\n        if col == 0:\n            axes[2, col].set_ylabel('Error')\n        axes[2, col].axis('off')\n    \n    plt.suptitle(f'Rollout ({rollout_steps} steps from {context_len} context frames)')\n    plt.tight_layout()\n    plt.show()\n    \n    # Compute MSE over time\n    mse_over_time = np.mean((predicted[:, 0] - gt_future[:, 0])**2, axis=(1, 2))\n    \n    plt.figure(figsize=(8, 4))\n    plt.plot(range(1, rollout_steps+1), mse_over_time)\n    plt.xlabel('Rollout Step')\n    plt.ylabel('MSE')\n    plt.title(f'Prediction Error vs Rollout Length (context={context_len})')\n    plt.grid(alpha=0.3)\n    plt.show()\n\n# Test at different context lengths\nfor ctx_len in [MIN_CONTEXT, MAX_CONTEXT]:\n    print(f\"\\n{'='*60}\")\n    print(f\"Context length: {ctx_len}\")\n    visualize_rollout(model, val_data, device, traj_idx=0, context_len=ctx_len, rollout_steps=30)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animated Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef animate_rollout_comparison(model, trajectories, device, traj_idx=0, context_len=8, rollout_steps=40):\n    \"\"\"Create side-by-side animation of prediction vs ground truth.\"\"\"\n    model.eval()\n    \n    # Get data\n    context = trajectories[traj_idx, :context_len].unsqueeze(0).to(device)\n    gt_future = trajectories[traj_idx, context_len:context_len+rollout_steps].cpu().numpy()\n    predicted = model.rollout(context, rollout_steps).cpu().squeeze().numpy()\n    \n    # Create animation\n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    \n    im_pred = axes[0].imshow(predicted[0, 0], cmap='gray', vmin=0, vmax=1)\n    axes[0].set_title('Predicted')\n    axes[0].axis('off')\n    \n    im_gt = axes[1].imshow(gt_future[0, 0], cmap='gray', vmin=0, vmax=1)\n    axes[1].set_title('Ground Truth')\n    axes[1].axis('off')\n    \n    error = np.abs(predicted[0, 0] - gt_future[0, 0])\n    im_err = axes[2].imshow(error, cmap='hot', vmin=0, vmax=0.5)\n    axes[2].set_title('Error')\n    axes[2].axis('off')\n    \n    title = fig.suptitle(f'Context={context_len}, t+1')\n    \n    def update(frame):\n        im_pred.set_array(predicted[frame, 0])\n        im_gt.set_array(gt_future[frame, 0])\n        error = np.abs(predicted[frame, 0] - gt_future[frame, 0])\n        im_err.set_array(error)\n        title.set_text(f'Context={context_len}, t+{frame+1}')\n        return [im_pred, im_gt, im_err, title]\n    \n    anim = animation.FuncAnimation(fig, update, frames=rollout_steps, interval=100, blit=False)\n    plt.close()\n    return HTML(anim.to_jshtml())\n\nanimate_rollout_comparison(model, val_data, device, traj_idx=0, context_len=MAX_CONTEXT, rollout_steps=40)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis: Does the Model Learn Physics?\n",
    "\n",
    "### Latent Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def analyze_latent_space(model, trajectories, device, num_traj=5):\n",
    "    \"\"\"Analyze what the latent space encodes.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode several trajectories\n",
    "    all_latents = []\n",
    "    for i in range(num_traj):\n",
    "        traj = trajectories[i].unsqueeze(0).to(device)  # (1, T, 1, H, W)\n",
    "        latents = model.encode_frames(traj).cpu().numpy()  # (1, T, latent_dim)\n",
    "        all_latents.append(latents[0])\n",
    "    \n",
    "    # Plot latent trajectories (first 3 dimensions)\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    ax1 = fig.add_subplot(131)\n",
    "    for i, latents in enumerate(all_latents):\n",
    "        ax1.plot(latents[:, 0], label=f'Traj {i}')\n",
    "    ax1.set_xlabel('Frame')\n",
    "    ax1.set_ylabel('Latent dim 0')\n",
    "    ax1.set_title('Latent Dimension 0 Over Time')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    ax2 = fig.add_subplot(132)\n",
    "    for i, latents in enumerate(all_latents):\n",
    "        ax2.plot(latents[:, 1], label=f'Traj {i}')\n",
    "    ax2.set_xlabel('Frame')\n",
    "    ax2.set_ylabel('Latent dim 1')\n",
    "    ax2.set_title('Latent Dimension 1 Over Time')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 2D projection of latent trajectory\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    for i, latents in enumerate(all_latents):\n",
    "        ax3.plot(latents[:, 0], latents[:, 1], 'o-', markersize=2, alpha=0.7, label=f'Traj {i}')\n",
    "        ax3.plot(latents[0, 0], latents[0, 1], 'go', markersize=8)  # Start\n",
    "        ax3.plot(latents[-1, 0], latents[-1, 1], 'ro', markersize=8)  # End\n",
    "    ax3.set_xlabel('Latent dim 0')\n",
    "    ax3.set_ylabel('Latent dim 1')\n",
    "    ax3.set_title('Latent Space Trajectory')\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_latent_space(model, val_data, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'history': history,\n",
    "    'config': {\n",
    "        'latent_dim': LATENT_DIM,\n",
    "        'n_heads': N_HEADS,\n",
    "        'n_layers': N_LAYERS,\n",
    "        'context_len': CONTEXT_LEN,\n",
    "    }\n",
    "}\n",
    "torch.save(checkpoint, 'results/model_checkpoint.pt')\n",
    "print(\"Model saved to results/model_checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key metrics to track:\n",
    "- **Single-step MSE**: How well does model predict 1 frame ahead?\n",
    "- **Rollout degradation**: How fast does error grow with longer rollouts?\n",
    "- **Visual quality**: Do predictions look like valid physics?\n",
    "- **Latent structure**: Does latent space encode position/velocity?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}